

# Bygge statistisk modeller

## Hensikten med modellbygging
Modellbygging er en av forskernes viktigste oppgaver. Vi bygger modeller for å predikere hva en person faktisk har skåret på den avhengige variabelen. 'Ok', sier du, ', men hvorfor skal vi bygge modeller når vi faktisk har målt personen sin prestasjon på den avhengige variabelen?'. Svaret på dette spørsmålet er at vi bygger modell fordi vi ønsker å forstå relasjonene mellom variablene vi har målt. Hvis vi klarer å bygge en god modell med variablene vi ha målt, så har vi en god forståelse av hvordan variablene henger sammen. Da vil modellen vår 


Hovedideen med slik modellbygging er at vi ønsker å bygge en statistisk modell til å predikere hva en person faktisk har hatt som skår på den avhengige variabelen. Til dette kan vi bruke en lineær modell som er en variant av følgende ligning:

$$
data_i = (modell) + error_i
$$

**Data** er den avhengige variabelen som vi har målt hos alle deltakerne og som vi kan bruke en modell til å predikere. Å predikere er et verb som benyttes mye i statistikken, og er synonymt med å forutsi. Min måte å tenke på det er at vi ønsker å si hva en person hadde som faktisk observasjon på den målte avhengig variabelen. Legg også merke til den lille *i*-en som står bak data og error i ligningen. Denne betyr individ, og sier at vi kan predikere et individ sin skår på den avhengige variabelen med modellen som vi har bygget.  **Modell** er egentlig bare en representasjon av denne dataen, mens **error** er hvor mye modellen bommer fra den faktisk observasjonen (dvs. data). Dette blir kanskje mer konkret om vi bruker et eksempel: 

La oss si at du er lege og at du får inn en pasient som sier hun har feber. Du vet at den normale kroppstemperaturen er 37 så dette blir modellen din. 

$$
data = 37 + error
$$
Det neste du gjør er å ta en febermåling av pasienten, og du måler kroppstemperaturen hennes til å være 40.

$$
40 = 37 + error
$$
Modellen din bommer derfor mer 3, fordi 40-37 = 3.

$$
40 = 37 + 3
$$
Formelt sett regner vi error for en hvilken som helst modell ved å få error alene i ligningen. 

$$
data = modell + error
$$
$$
error = data - modell
$$
$$
3 = 40 - 37
$$
Dette var en superenkel modell, men viser hvordan vi kan bruke slike modeller. Ofte bygger vi ikke modeller for ett individ, men flere. Tenk bare hvor mange deltakere vi har med i en studie.  Modellen vi bygger bør være en god representasjon av alle disse individene. Med andre ord bør erroren være så liten som mulig. **Dette er essensielt!** Vi ønsker å bygge statistiske modeller som er gode, og vi ønsker å sammenligne ulike modeller for å se hvilke av disse modellene som reduserer erroren mest mulig.


Det er en mer presis og korrekt måte å skrive ligningen over på, og som du ofte ser i artikler og statistikkbøker:

$$
data = (modell) + error
$$
$$
data = (b_0) + error
$$



$$
Y_i = (b_0 + b_1X_i) + error
$$
Her er $ **Y_i** $ den avhengige variabelen som vi faktisk har målt for et individ, *i*. **X_i** er dette individets faktiske måling på variabel X, som vi ofte kaller for prediktorvariabel. Som det fremgår av den siste ligningen har også $ b1 $ hektet på seg. Denne forteller oss forholdet mellom prediktorvariabelen (Xi) og den avhengig variabelen (). Vi skriver den liten liten *b* fordi dette er noe vi estimerer fra et utvalg. **b0** er vår prediksjon når Xi er **null** og **0**. 

I figurene under ser tre ulike modelle med uinteressante X og Y variabler. Alle har samme b0, mens de har forskjellig b1. Husk at b1 forteller om forholdet mellom X og Y. I modell A ser du at når X øker så øker Y med 0.4 for hver enhets økning i X. I modell B er det ingen relasjon mellom X og Y, så for en enhets økning X, vil Y være den samme. I modell C er det en negativ relasjon mellom X og Y. Denne modellen sier at for en enhets økning i X, vil vi forvente Y går ned med 0.4 (siden den er negativ).


\begin{figure}

{\centering \includegraphics[width=1\linewidth]{04-h0_files/figure-latex/unnamed-chunk-2-1} 

}

\caption{**CAPTION THIS FIGURE!!**}(\#fig:unnamed-chunk-2)
\end{figure}


### Test kunnskapen din
La oss si at vi hatt med et målt et individ sin **X** og **Y** (du kan bytte ut X og Y med hvilken som helst variabel (f.eks. høyde, vekt), hvis du vil). Individet sitt mål på X er 8. Hvis du bruker modell A, hva vil du forvente at denne personen har på *Y*?

<input class='solveme nospaces' size='3' data-answer='["9.2"]'/>.

I figuren ser du tre modeller som har ulike b1, men samme b0. b0 er verdien på Y når X = null/0.


\begin{figure}

{\centering \includegraphics[width=1\linewidth]{04-h0_files/figure-latex/unnamed-chunk-3-1} 

}

\caption{**CAPTION THIS FIGURE!!**}(\#fig:unnamed-chunk-3)
\end{figure}
### Test kunnskapen din
La oss si at vi hatt med et målt et individ sin **X** og **Y** (du kan bytte ut X og Y med hvilken som helst variabel (f.eks. høyde, vekt), hvis du vil). Individet sitt mål på X er 3. Hvis du bruker modell B, hva vil du forvente at denne personen har på *Y*?

<input class='solveme nospaces' size='3' data-answer='["4.2"]'/>.


## Modellbygging med 'Null-Hypothesis Significance Testing (NHST)'
Nå som du har en fått en innføring i hvordan du kan bygge modeller er det på tide at vi begynner å spesifisere hvilke modeller vi skal bygge. Som du sikkert er kjent med jobber forskere innenfor et paradigme som kalles for **Null-Hypothesis Significance Testing (NHST)**. Dette går ut på at forskeren fremstiller to hypoteser:

1. **H0**: En null-hypotese som sier at det ikke er noen effekt (f.eks. ingen forskjeller mellom grupper, ingen sammenheng mellom variablene)
2. **H1**: En alternativ/eksperimentell hypotese som sier at det er en effekt (f.eks. det er en forskjell mellom gruppene)

For å teste disse hypotesene må forskeren bygge to modeller: en modell for null-hypotesen (vi kaller denne for **null-modellen**) og en **alternativ-modell**. Vi regner ut hvor mye error det er i hver av disse modellene for å se hvilke av disse modellene det er klokt å benytte. Husk at målet er å benytte modeller som er gode og som har lite error. Hvis null-modellen er god nok, så er det ikke noe poeng å bruke den alternative modellen. Men hvis den alternative modellen er mye bedre enn null-modellen, da bør benytte denne. Forskeren gjennomfører deretter en **statistisk test** som representerer den alternative hypotesen. Utfallet av testen er en **verdi**, for eksempel en *z-verdi*, *t-verdi* eller *f-verdi*, som vi kan bruke til å regne ut sannsynligheten for, gitt at null-hypotesen er sann. Forskjellige tester opererer med forskjellige navn på verdiene sine (sorry, men det er bare slik det er). 


\begin{figure}

{\centering \includegraphics[width=1\linewidth]{04-h0_files/figure-latex/unnamed-chunk-4-1} 

}

\caption{**CAPTION THIS FIGURE!!**}(\#fig:unnamed-chunk-4)
\end{figure}



## Null-modellen (null-hypotesen)
I vår studie ønsker vi å teste om det er forskjeller mellom de to gruppene som har blitt disponert for ulikt treningsopplegg (3 versus 1 sett). Husk at vi har laget en variabel hvor vi har kodet disse som 0 og 1. Null-hypotesen er at det ikke er noen forskjeller mellom gruppene. En annen måte å formulere dette på er om vi blir bedre til å predikere et individs skår hvis vi vet hvilken gruppe de tilhører eller om vi kun trenger en enkel modell. Den enkleste modellen vi kan benytte er gjennomsnittet i % fremgang 1RM for alle deltakerne. Dette er modellen som representerer null-hypotesen. Med andre ord vår null-modell

$$
Y_i = (b_0) + error
$$
$$
fremgang.1RM = (mean) + error
$$ 
Det er ofte enklere å se denne modellen i tabellform, slik som dere ser under.




<table>
<caption>(\#tab:unnamed-chunk-6)Null-modellen (mean)</caption>
 <thead>
  <tr>
   <th style="text-align:right;"> individ </th>
   <th style="text-align:left;"> gruppe </th>
   <th style="text-align:right;"> rm </th>
   <th style="text-align:right;"> modell.mean </th>
   <th style="text-align:right;"> error </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 40.467 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 8.305 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 2 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 49.072 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 16.910 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 47.941 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 15.779 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 44.514 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 12.352 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 52.288 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 20.125 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 6 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 40.018 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 7.855 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 7 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 49.484 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 17.322 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 8 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 29.210 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -2.952 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 9 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 40.593 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 8.431 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 10 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 37.587 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 5.424 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 11 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 35.427 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 3.264 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 12 </td>
   <td style="text-align:left;"> tre.sett </td>
   <td style="text-align:right;"> 42.494 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 10.331 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 13 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 17.706 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -14.457 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 14 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 17.072 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -15.091 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 18.268 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -13.894 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 16 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 25.426 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -6.736 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 17 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 32.703 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> 0.541 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 18 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 19.102 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -13.060 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 19 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 22.238 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -9.924 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 20 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 22.271 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -9.891 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 21 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 26.179 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -5.983 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 22 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 20.349 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -11.814 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 23 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 23.528 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -8.635 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 24 </td>
   <td style="text-align:left;"> ett.sett </td>
   <td style="text-align:right;"> 17.960 </td>
   <td style="text-align:right;"> 32.162 </td>
   <td style="text-align:right;"> -14.203 </td>
  </tr>
</tbody>
</table>



La oss prøve hvordan denne modellen virker. For individ 1 målte vi en fremgang i 1RM underkropp på **40.467**, men modellen vår sa **32.162**. Så modellen bommet med 8.305, dvs. en error på **8.305**.
$$
fremgang.1RM = (mean) + error
$$
$$
40.467 = 32.162 + 8.305
$$ 
Prøv modellen du også: For individ nr. 8, sier modellen at individet hadde en skår på <input class='solveme nospaces' size='6' data-answer='["32.162"]'/>, men denne personen hadde faktisk en skår på <input class='solveme nospaces' size='6' data-answer='["29.210"]'/>. Modellen bommet derfor med <input class='solveme nospaces' size='6' data-answer='["-2.952"]'/>. 

Vi kan fortsette slik for alle deltakerne vi har hatt med i studien. Husk at vi ikke er interessert i hvir mye bommer for hvert enkelt individ, men for alle indivene. Summer derfor all erroren for alle indidene, hvilket tall får du da?  <select class='solveme' data-answer='["null","0"]'> <option></option> <option>null</option> <option>0</option> <option>3</option> <option>-3</option></select>. (tenk over hvorfor du får dette svaret før du leser videre)

Som du så i forrige oppgave blir det feil å summere alle erroren, men ved å regne **Sum of Squared Error** løser vi dette problemet effektivt. Det vi gjør er å gange error med seg selv (error^2) før vi summerer alt dette sammen.


Hvis vi regner ut  **Sum of Squared Error** for null-modellen fpr vi: <input class='solveme nospaces' size='8' data-answer='["3243.784"]'/>. Dette tallet er viktig! Dette er null-hypotesen vår. Hvis det ikke er noen forskjell mellom de to treningsgruppene våre er det like greit å bruke denne null-modellen. Men hvis vi finner ut at modellen vår blir bedre (dvs. reduserer Sum of Squared Error) ved å legge til en prediktorvariabel som består er av gruppevariabelen vår, da bør vi gjøre dette. 

Før du går videre er det greit å visualisere hvordan null-hypotesen ser ut rent visuelt. Den prikkete streken i figuren under representerer modellen vår som er mean. Som du ser, så gjør den ingen justeringer for de ulike individene. Erroren er avstanden fra den linjen og opp til hvert datapunkt.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{04-h0_files/figure-latex/unnamed-chunk-8-1} 

}

\caption{**CAPTION THIS FIGURE!!**}(\#fig:unnamed-chunk-8)
\end{figure}


## H1: Alternativ modell (alternativ hypotese)
I forrige avsnitt sa vi at **null-hypotesen (H0)** reresenterer en en modell som gir samme prediksjon for alle deltakerne som var med i studien uavhengig av hvilken treningsgruppe de tilhører. Vi kalte denne for null-modellen. Vi regnet oss også frem til at denne modellen ga oss en Som of Squared error på 3243.784.

$$
Y_i = (b_0) + error_i
$$ 
$$
Fremgang.1RM_i = (mean) + error_i
$$ 

Spørsmålet vi skal stille i dette avsnittet er om vi kan redusere error fra denne ved å benytte en mer kompleks modell som benytter (vår dummykodede kategoriske variabel) som prediktorvariabel:
$$
Y_i = (b_0 + b_1X_i) + error
$$ 
Prediktorvariabelen b1 er en gruppevariabelen vår som vi dummykodet med tallene 0 og 1. 

$$
Fremgang.1RM_i = b_0 + b_1(Gruppe) + error_i
$$ 
For å fokusere på holde dette på et overordnet nivå, så vil jeg gi dere de estimerte verdiene for b0 og b1. Målet er å vise dere hvordan denne modellen fungerer. Senere skal gå gjennom hvordan vi regner ut disse verdiene.

$$
Fremgang.1RM_i = b_0(21.90) + b_1(20.52*Gruppe) + error_i
$$ 
Modellen sier at vi har en intercept på 21.90. Dette er forventede verdien på Y (Fremgang.1RM) når prediktorvariabelen er 0. Modellen sier også at b1 er 20.52.  Med andre ord den forventede økning i Y for en enhets økning i X. Husk at vi lagde en gruppe-variabel der vi kodet de to gruppene våre med 0 og 1. Så hvis et individ tilhørte gruppe 0, blir vår prediksjon:

$$
Fremgang.1RM_i = 21.90 + b_1(20.52*0) + error_i
$$ 
0*20.52 = 0, så blir stående igjen med b0, vår prediksjon av Y når er nulll
$$
Fremgang.1RM_i = 21.90 + 0 + error_i
$$ 
$$
Fremgang.1RM_i = 21.90 + error_i
$$ 
Hvis individet derimot tilhører 1 predikerer modellen at individet sin skår blir 42.48.

$$
Fremgang.1RM_i = 21.90 + b1(20.52*1) + error_i
$$ 
$$
Fremgang.1RM_i = 42.48 + error_i
$$ 
Visualisert fremstilt blir modellen vår seendes slik ut:


```r
ggplot(dat, aes(dummykodet, rm, color=dummykodet)) +
  geom_point()+
  scale_y_continuous(breaks = seq(0, 60, 5)) +
  coord_cartesian(ylim = c(0, 60)) +
  geom_jitter(width = 0.2) + 
  stat_summary(geom = "line", fun = mean, group = 1, color="black", linetype="dotted", size=1.2) +
  labs(y="% fremgang 1RM underkropp", x="Dummykodet variabel") +
  theme_bw()
```

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{04-h0_files/figure-latex/unnamed-chunk-9-1} 

}

\caption{**CAPTION THIS FIGURE!!**}(\#fig:unnamed-chunk-9)
\end{figure}


**Oppgaver**
Tabellen under viser 6 individer som tilhørte treningsgruppe. Du ser deres faktiske fremgang i 1RM kolonnen. La oss bruke det vi har lært til å predikere disse personene sin fremgang. Vi bruker samme modell som over

$$
Fremgang.1RM_i = b_0(21.90) + b_1(20.52*Gruppe) + error_i
$$ 
a) Hva predikerer modellen at individ nummer 3 hadde i skår? (to desimaler)

<input class='solveme nospaces' size='5' data-answer='["42.42"]'/>

b) Hva hadde individ nr i skår?

<input class='solveme nospaces' size='6' data-answer='["47.941"]'/>

c) hvor mye error blir det? 

<input class='solveme nospaces' size='5' data-answer='["5.521"]'/>

d) i Squared Error blir denne erroren?

<input class='solveme nospaces' size='8' data-answer='["30.48144"]'/>

e) nå som du har jobbet med denne modellen, så lurer jeg på om det er noe kjent med disse verdiene i modellen. Gå tilbake til [link] hvis du trenger et hint.

bo er <input class='solveme nospaces' size='14' data-answer='["gjennomsnittet"]'/> (norskt ord) for gruppen som er kodet med 0. b1 er <input class='solveme nospaces' size='11' data-answer='["forskjellen"]'/> (norsk ord) mellom gruppen som er kodet med 0 og gruppen som er kodet med 1. b0 + b1<input class='solveme nospaces' size='14' data-answer='["gjennomsnittet"]'/> (norsk ord) for gruppen som er kodet med 1.




\begin{table}

\caption{(\#tab:unnamed-chunk-11)Dummy koding}
\centering
\begin{tabular}[t]{r|l|r|r}
\hline
individ & gruppe & rm & dummykodet\\
\hline
1 & tre.sett & 40.467 & 1\\
\hline
2 & tre.sett & 49.072 & 1\\
\hline
3 & tre.sett & 47.941 & 1\\
\hline
4 & tre.sett & 44.514 & 1\\
\hline
5 & tre.sett & 52.288 & 1\\
\hline
6 & tre.sett & 40.018 & 1\\
\hline
\end{tabular}
\end{table}

I forrige oppgave regnet du ut error for ett enkelt individ. Men vi er interessert i den totale erroren for modellen. Formelen for denne er: 

total error in den alternative modellen:


SS_R = $\sum_{n=1}^N (observert_i - modell_i)^2$ 

Med andre ord er det kvadraten av den faktiske observasjonen - hva modellen sa. Bruk formelen til å regne ut dette. (to desimaler

<input class='solveme nospaces' size='7' data-answer='["2527.50"]'/>

## Variansanalyse (ANOVA-tabell)
Nå som vi har regnet ut hvor mye error det er i hver av disse modellene - null-modellen og den alternative modellen - er det klart for å gjøre en sammenligning av disse modellene. Modellene vi sammenligner er om alternative-modellen reduserer error mer enn null-modellen. Fra figurene under kan det slik ut; linjen til høyre ser ut til å ligge nærmere observasjonene enn linjen i figuren til venstre.


\begin{figure}

{\centering \includegraphics[width=1\linewidth]{04-h0_files/figure-latex/unnamed-chunk-12-1} 

}

\caption{**CAPTION THIS FIGURE!!**}(\#fig:unnamed-chunk-12)
\end{figure}
**The total sum of squares (SS<sub>T</sub>)** = **3243.784**
(SS<sub>T</sub>) er hvor mye error vi får ved å bruke null-modellen.

**The residual sum of squares (SS<sub>R</sub>)** = **716.3** 
(dette er hvor mye error som er igjen etter at vi brukte modellen vår)


En naturlig ting å gjøre er å regne hvor mye error den alternative modellen vår har redusert error med. Man kaller denne for **The model sum of squares (SS<sub>M</sub>)**:

**The model sum of squares (SS<sub>M</sub>)** = **(SS<sub>T</sub>)** - **(SS<sub>R</sub>)** = <input class='solveme nospaces' size='6' data-answer='["2527.5"]'/>

Hvis vi regner hvor mye error modellen vår har redusert error med, så kan vi se at modellen vår har redusert error med 78 %. Dette er ekstremt mye, og det er sjeldent man finner en så høy prosent. Denne verdien har mange forskjellige navn i statistikken, *proportional reduction in error (PRE)", R2 og n2". Og den er viktig. Jeg velger å bruke R2.

$$
R2 = (SS_T - SS_R) / SS_T
$$
$$
R2 = (3243.784 - 716.3) / 3243.784 
$$


$$
R2 = 0.7791826
$$
Når dere bygger statistiske modeller i R,Jamovi eller SPSS vil dere få en ANOVA-tabell de. Her ser du de samme verdiene som vi har regnet manuelt.


```r
#aov er en forkortolse for analysis of variance (ANOVA)
#dette er funksjon som kommer mer R.
aov(rm ~ dummykodet, dat)
```

```
## Call:
##    aov(formula = rm ~ dummykodet, data = dat)
## 
## Terms:
##                 dummykodet Residuals
## Sum of Squares   2527.4962  716.2875
## Deg. of Freedom          1        22
## 
## Residual standard error: 5.706008
## Estimated effects may be unbalanced
```
## F-test




```
## # A tibble: 24 x 6
##       ss sum.ss mod.m  error sum.error   pre
##    <dbl>  <dbl> <dbl>  <dbl>     <dbl> <dbl>
##  1  8.30  3244.  42.4   3.81      716. 0.779
##  2 16.9   3244.  42.4  44.3       716. 0.779
##  3 15.8   3244.  42.4  30.5       716. 0.779
##  4 12.4   3244.  42.4   4.38      716. 0.779
##  5 20.1   3244.  42.4  97.4       716. 0.779
##  6  7.86  3244.  42.4   5.77      716. 0.779
##  7 17.3   3244.  42.4  49.9       716. 0.779
##  8 -2.95  3244.  42.4 174.        716. 0.779
##  9  8.43  3244.  42.4   3.34      716. 0.779
## 10  5.42  3244.  42.4  23.4       716. 0.779
## # ... with 14 more rows
```


## T-test
ANOVA. En annen måte vi kan teste om det er forskjeller mellom to grupper er å teste om det er forskjeller er å kjøre en uavhengig t-test. Ofte sier man at det - Og når ikke. Men har istf. valgt å bygge opp den statistiske kunnskapen vår ved å kjøre en ligning. Så når blir ikke forskjellen så stor.






