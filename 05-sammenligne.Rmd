# Sammenligne modeller

```{r echo=FALSE}
set.seed(2002) #viktig å ha med denne for å få nøyaktig samme datasett
tre.sett <- rnorm(n = 12, mean = 41, sd = 5) #12 individer
ett.sett <-rnorm(n = 12, mean = 21, sd = 5) #12 individer

#lager en tibble fra tidyverse-pakken. Må ha lastet inn tidyverse library(tidyverse) i scriptfilen
dat <- tibble(individ = seq(1:24),
              gruppe = rep(c("tre.sett ", "ett.sett"), c(length(tre.sett), length(ett.sett))),
              rm = c(tre.sett , ett.sett))


#lager et nytt objekt som heter dummykodet.dat
dat <- dat %>%
  # her lager jeg en ny kolonne som heter dummykoder. If gruppe == 'ett.sett', gi verdien 0, else gi de 1.
  mutate(dummykodet = if_else(gruppe == "ett.sett", 0, 1)
  )


dat <- dat %>%
  # her lager jeg en ny kolonne som heter dummykoder. If gruppe == 'ett.sett', gi verdien 0, else gi de 1.
  mutate(kontrast = if_else(gruppe == "ett.sett", -0.5, 0.5)
  )

dat <- dat %>%
  mutate(dummykodet = as.factor(dummykodet),
         kontrast = as.factor(kontrast))


```

Nå som vi har bygget de to statistiske modellene - **en null-modell** og **en alternativ modellen** - hva skal vi gjøre videre? Det vi sitter igjen med er en **error** (les sum of squared error) for null-modellen og en error for alternative modellen. Vår neste oppgave er å finne en måte å **sammenligne disse modellene** på. For å gjøre det helt eksplisitt og tydelig, skal vi nå sammenligne om modellen til høyre er bedre enn modellen til venstre. 

<div class="info">
Når vi sier at en modell er bedre, så mener vi at den verticale avstanden fra linjen til datapunktene er kort. Hvis det er stor vertical avstand fra datapunktet til linjen for mange individer, har vi en dårlig  modell.
</div>

```{r echo=FALSE, fig.width=6, fig.height=2.5, fig.cap='Modeller med forskjellig b1'}
a <-ggplot(dat, aes(dummykodet, rm, color=dummykodet)) +
  geom_point()+
  scale_y_continuous(breaks = seq(0, 60, 5)) +
  coord_cartesian(ylim = c(0, 60)) +
  geom_jitter(width = 0.2) + 
  geom_hline(yintercept=32) +
  labs(y="% fremgang 1RM underkropp", x="Dummykodet variabel", title="Null-modell") +
  guides(fill=FALSE) +
  theme_bw()


b <- ggplot(dat, aes(dummykodet, rm, color=dummykodet)) +
  geom_point()+
  scale_y_continuous(breaks = seq(0, 60, 5)) +
  coord_cartesian(ylim = c(0, 60)) +
  geom_jitter(width = 0.2) + 
  stat_summary(geom = "line", fun = mean, group = 1, color="black") +
  labs(y="% fremgang 1RM underkropp", x="Dummykodet variabel", title="Alternativ-modell") +
  theme_bw()

library(cowplot)

plot_grid(a, b, nrow = 1)



````
## ANOVA-tabell (variansanalyse)
En måte vi kan sammenligne modeller på er å bruke en ANOVA-tabell. Dette er en ganske vanlig tabell som dere kommer til å se flere ganger. Dere har allerede regnet ut all nødvendig informasjon for å lage en ANOVA-tabell, så dere kan lage den selv.

**ANOVA-tabell**

Modell | SS | *df* | MS | *F* | $R^2$ | *p*-verdi
------------- | ------------- | ------------- | ------------- | ------------- | -------------
The model sum of squares (SS<sub>M</sub>) | `r fitb(2527.5)` |  | | |  |
The residual sum of squares (SS<sub>R</sub>) | `r fitb(716.2875)` | | | | |
The total sum of squares (SS<sub>T</sub>) | `r fitb(3243.784)` | | | | |

**Oppgave**

a. Hva er sum of squared error for null-modellen? 

>(Sett dette inn i total sum of squares (SS<sub>T</sub>)

b. Hva er sum of squared error for den alternative modellen?

>(Sett dette inn i residual sum of squares (SS<sub>R</sub>). Dette er error som er igjen etter at man har brukt den alternative-modellen. Men >>andre ord. Man kalles dette residuals.

c. Hvor mye sum of squared error er redusert ved å bruke den alternative modellen i forhold null-modellen?

>(Sett dette inn i residual sum of squares (SS<sub>R</sub>).Dette kalles The model sum of squares (SS<sub>M</sub>) eller regression i statistiske programmer. 

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Godt jobbet!</span>

<div class="info">
Det kan noen ganger være greit å visualisere erroren som er igjen med de to modellene, pluss hvor mye error som er redusert ved å bruke den alternative modellen istf. å bruke null-modellen. I figuren til venstre ser du de modellene våre pluss hvor mye error den alternative modellen vår har redusert error med:

```{r echo=FALSE, fig.width=5, fig.height=4, out.width='60%', fig.cap='Visualisering av error ved de ulike modellene'}
SSE <- c(3243.784, 2527.5, 716.3)
SS <- c('sst', 'ssm', 'ssr')
bar <- tibble(SSE, SS)

 a <- ggplot(bar, aes(x = SS, y = SSE, fill = SS)) +
  geom_col(color="black") +
  scale_x_discrete(limits = rev) +
  labs(x="Modellene", y="Sum of Squared Error (SSE)") +
  theme_bw()

SSE_ny <- c(3243.784, 100, 3143.784)
SS_ny <- c('sst', 'ssm', 'ssr')
bar_ny <- tibble(SSE_ny, SS) 
 
b <- ggplot(bar, aes(x = SS_ny, y = SSE_ny, fill = SS_ny)) +
  geom_col(color="black") +
  scale_x_discrete(limits = rev) +
  labs(x="Modellene", y="Sum of Squared Error (SSE)") +
  theme_bw()

library(cowplot)

plot_grid(a, b, nrow = 1)

```

* SS<sub>T</sub> representerer den totale erroren (dvs. erroren vi fikk ved å bruke null-modellen)
* SS<sub>R</sub> representerer hvor mye error som er igjen etter at vi brukte den alternative modellen. 
* SS<sub>M</sub> er hvor mye error som modellen vår klarte å forklare. 

</div>

e. Hvis du sammenligner med figuren til høyre (som kun er brukt et eksempel), vil du si at vår alternative modell er god?

`r mcq(c(answer = "ja", "nei"))`. 

d. Hva er (SS<sub>T</sub>) - (SS<sub>R</sub>)? 

`r fitb(2527.5)`

e. Hva er (SS<sub>R</sub>) + (SS<sub>M</sub>)? 

`r fitb(3243.784)`

Med erroren vi har tilgjengelig kan vi regne noe som heter proporsjonal feilreduksjon (proportional reduction in error (PRE)). Hvis vi multipliserer dette tallet med 100 (* 100) få du hvor mange % modellen vår har redusert error med, i forhold til null-modellen. Dette er et en effektstørrelse som ofte blir rapoortert med i ANOVA eller regresjonsanalyser. I ANOVA ser du at man rapporterer denne som $n^2$, mens man i regresjonsanalyser kaller denne for $R^2$
. Vi regner ut det på følgende måte:

$$
R^2 = \frac{(SS_T - SS_R)}{SS_T} * 100
$$

e. Hvilken verdi får du hvis du regner (SS<sub>M</sub>/ (SS<sub>T</sub>)) * 100?

`r fitb(78)` (uten %-tegnet)

>>Det er dessverre mange forskjellige navn på denne verdien. Du vil se at folk bruker PRE, $n^2$. Vit at de mener det samme.



<span style="font-size: 22px; font-weight: bold; color: var(--green);">Ferdig - Bra jobbet!</span>

## Teste (statistisk) om vår alternative modell forklarer mer varians enn null-modellen
Det kan høres ut som at en error-reduksjon på 2527.5 ($SS_M$), eller 78 % ($(R^2)*100$), er mye. Et problem med $SS_M$ og $R^2$ er at begge er garantert å øke i takt med antall parametere vi legger til i modellen. Dere har ikke lært dette enda, men vit at vi kunne bygget en modell der vi inkluderer kjønn, alder, treningsstatus som prediktorvariabler. Da ville dere fått en mer kompleks modell:

$$
Y_i  = b_0 + b_1(Gruppe_i) + b_2(Kjønn_i) + b_3(Treningstatus_i) + b_4(Alder_i)
$$

Hvis vi hadde gjort dette, ville vi fått en høy $SS_M$ eller $R^2$ uansett (aldri lavere). Derfor er det mer interessant å regne ut gjennomsnittlig $SS_M$ per parameter vi har lagt til i modellen (i forhold til null-modellen). Dette kalles Mean Squared Model (MSM), eller gjennomsnittlig squared error for den alternative modellen, og regnes på følgende måte:

$$
\text{ Mean Squared Model } (MS_M) = SS_M / df_M
$$
$df_m$ står for antall frihetsgrader som er lagt til i modellen utover null-modellen. Null-modellen har kun ett parameter ($b_0$), som er mean, mens vår alternative modell har to parametere ($b_0$ og $b_1$). Derfor blir $df_M$ = (2-1) = 1. 

a. Regn ut Mean Squared Error ($MS_M$) og sett det verdien inn i ANOVA-tabellen vår

**ANOVA-tabell**

Modell | SS | *df* | MS | *F* | $R^2$ | *p*-verdi
------------- | ------------- | ------------- | ------------- | ------------- | -------------
The model sum of squares (SS<sub>M</sub>) | 2527.5 |  |  `r fitb(2527.5)` || 0.78 |
The residual sum of squares (SS<sub>R</sub>) | 716.2875 | | | | |
The total sum of squares (SS<sub>T</sub>) | 3243.784 | | | | |

<div class="info">
Det vi ønsker at dere tar med dere fra denne oppgaven er at en høy $SS_M$ eller $R^2$ er **mer imponerende hvis vi kun har lagt til ett ekstra parameter enn hvis vi hadde lagt til f.eks. 10 parametere**. Enig?
</div>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Bra!</span>

Det siste vi skal gjøre er å sammenligne $MS_M$ med $MS_R$. **$MS_R$** er $SS_R$, den erroren som er igjen etter at vi har brukt den alternative modellen, **delt på antall parametere som i prinsippet kunne vill lagt til i modellen**. I prinsippet står vi fritt til å legge til så mange parametere i modellen som vi ønsker, men antall parametere kan aldri overstige antall deltakere i studien. Men fordi vi allerede har brukt to parametere i den alternative modellen, kan vi kun  legge til (24 - 2) = 22 parametere.

$$
\text{ Mean Squared Residual (MSR) }  = SS_R / df_R
$$
b. Regn ut Mean Squared Residual ($MS_R$) og sett det verdien inn i ANOVA-tabellen vår

**ANOVA-tabell**

Modell | SS | *df* | MS | *F* | $R^2$ | *p*-verdi
------------- | ------------- | ------------- | ------------- | ------------- | -------------
The model sum of squares (SS<sub>M</sub>) | 2527.5 |  | 2527.5 |  | 0.78 |
The residual sum of squares (SS<sub>R</sub>) | 716.2875 | | `r fitb(32.55852)` |  | |
The total sum of squares (SS<sub>T</sub>) | 3243.784 | | | | |

<div class="info">
$MS_R$ er gjenstående error per parameter som potensielt kunne blitt lagt til i modellen. Med andre ord er det den gjennomsnittlige erroren som er igjen per parameter som kunne blitt lagt til i modellen. Enig?
</div>


<span style="font-size: 22px; font-weight: bold; color: var(--green);">Vi er endelig i mål!</span>

Nå har vi gjort alle utregningene, og vi kan bare sammenligne disse to størrelsene ($MS_M$ versus $MS_R$) med hverandre. Dette kalles en **F-test**.

$$
\text{F}  = \frac{MS_M}{MS_R}
$$

c. Regn ut vår F-verdi og sett den inn i vår ANOVA-tabell

**ANOVA-tabell**

Modell | SS | *df* | MS | *F* | $R^2$ | *p*-verdi
------------- | ------------- | ------------- | ------------- | ------------- | -------------
The model sum of squares (SS<sub>M</sub>) | 2527.5 | 1 | 2527.5 | `r fitb(77.63)` | 0.78 | p < 0.001
The residual sum of squares (SS<sub>R</sub>) | 716.2875 | 22 | 32.55852 |  | |
The total sum of squares (SS<sub>T</sub>) | 3243.784 | | | | |

Vi kan se at vår F-verdi er 77.63, og at p-verdien er < 0.001. Denne verdien (vises kke i figuren under pga. størrelsen) er høyere enn vår kritiske verdi (den røde streken) for 0.05 ved $df_M$ = 1 og $df_R$ = 22. Vi sier derfor at vår modell er signifikant, hvilket vil si at den har forbedret vår evne til å predikere utfallsvariabelen. 

```{r echo=FALSE, fig.width=5, fig.height=4, out.width='60%', fig.cap='F-test'}
data.frame(f = 0:1000 / 100) %>% 
           mutate(df_1_22 = df(x = f, df1 = 1, df2 = 22)) %>%
  gather(key = "df", value = "density", -f) %>%
ggplot() +
  geom_line(aes(x = f, y = density), color="#00BFC4") +
  labs(title = "F-fordelingen ved vår frihetsgrad (df) på 1 og 22",
       x = "F",
       y = "Tetthet") +
  geom_segment(aes(x = 4.30, y = 0, xend = 4.30, yend = 2), linetype = "dashed", col = "red")+
  theme_bw()


````

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Done!</span>

Da er det bare å sette seg tilbake å nyte denne sangen:

<iframe width="600" height="350" src="https://www.youtube.com/embed/XHR3Rpij42Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

![Slik designet Rønnestad et al. (2007) sin studie](F.png)


Det siste vi kan gjøre er å teste om parameterne vi har lagt til i modellen er god. og en F-fordeling. En F-fordeling ser veldig lik ut som en z og t-fordeling og fungerer på samme måte: Vi regner ut en F-verdi, og spør fra sannsynligheten er for å oppnå en slik verdi gitt at null-hypotesen er sann. Null-hypotesen i en F-test er at den alternative modellen ikke forklarer noe varians. Med andre ord at $R^2$ = 0. For å teste dette må vi regne ut en F-verdi:

$$
F = \frac{(SS_M / df_M)}{SS_R / df_R}
$$
Vi har allerede regne ut, så vi kan plotte disse inn.

$$
F = \frac{2527.5/ df_M}{716.2875 / df_R}
$$




Hvis dette ikke var forståelig foreslår jeg følgende tutorials:
- https://www.youtube.com/watch?v=eSJAjlavPwU
- https://www.youtube.com/watch?v=0xWDulRHd9M
- https://www.youtube.com/watch?v=iAE4UeoVE9A
- https://www.youtube.com/watch?v=OK4Xns4zabs



```{r}
#aov er en forkortolse for analysis of variance (ANOVA)
#dette er funksjon som kommer mer R.
summary(aov(rm ~ dummykodet, dat))

```


```{r echo=FALSE}
ok <- dat %>%
  summarise(ss = rm - mean(rm),
            sum.ss = sum(ss^2),
            mod.m = if_else(dummykodet == 0, 21.90, 42.42),
            error = (rm - mod.m)^2,
            sum.error = sum(error),
            pre = (sum.ss - sum.error) / sum.ss
            )

```



